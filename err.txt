NVIDIA: no NVIDIA devices found
WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: unknown error)
train_x: [ 37.5  50. ]train_Y:0.0net cost: 0.970266513152
train_x: [ 0.  0.]train_Y:0.04net cost: 0.885369067986
train_x: [ 0.  0.]train_Y:0.01net cost: 0.930329168629
train_x: [ 0.  0.]train_Y:0.02net cost: 0.888103905731
train_x: [ 0.  0.]train_Y:0.01net cost: 0.856046871411
train_x: [ 0.  0.]train_Y:0.01net cost: 0.705085877518
train_x: [ 0.  0.]train_Y:0.02net cost: 0.217502382521
train_x: [ 0.  0.]train_Y:0.02net cost: 0.0100853769083
train_x: [ 0.  0.]train_Y:0.01net cost: 0.00863664028261
train_x: [ 54.6875  54.6875]train_Y:0.01net cost: 0.00647947588308
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.0066965779396
train_x: [ 1.66015625  1.66015625]train_Y:0.01net cost: 0.00415688116406
train_x: [ 77.1484375  77.1484375]train_Y:0.02net cost: 0.00245400413181
train_x: [ 4.8828125  4.8828125]train_Y:0.01net cost: 0.00315472252657
train_x: [ 1.66015625  1.66015625]train_Y:0.04net cost: 0.000514743957563
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.00264168739779
train_x: [ 4.8828125  4.8828125]train_Y:0.02net cost: 0.0014913476805
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 0.00134626157506
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.00202231135543
train_x: [ 4.8828125  4.8828125]train_Y:0.01net cost: 0.00184768529297
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 0.000974170141303
train_x: [ 77.1484375  77.1484375]train_Y:0.03net cost: 0.000399946649086
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.00242583050166
train_x: [ 1.66015625  1.66015625]train_Y:0.01net cost: 0.00140513609438
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.00131219278414
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.00203090248103
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 0.000561479022922
train_x: [ 77.1484375  77.1484375]train_Y:0.03net cost: 0.000169297686892
train_x: [ 4.8828125  4.8828125]train_Y:0.02net cost: 0.000512826274941
train_x: [ 1.66015625  1.66015625]train_Y:0.01net cost: 0.00102535641143
train_x: [ 77.1484375  77.1484375]train_Y:0.0net cost: 0.00169456146006
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.00160877818675
train_x: [ 1.66015625  1.66015625]train_Y:0.0net cost: 0.00153118830509
train_x: [ 77.1484375  77.1484375]train_Y:0.02net cost: 0.000331923575338
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.00142963918811
train_x: [ 1.66015625  1.66015625]train_Y:0.01net cost: 0.000728198507085
train_x: [ 77.1484375  77.1484375]train_Y:0.03net cost: 4.11995760011e-05
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.00131675665234
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 0.000241943092659
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.000637604712394
train_x: [ 4.8828125  4.8828125]train_Y:0.01net cost: 0.000613410423763
train_x: [ 1.66015625  1.66015625]train_Y:0.01net cost: 0.000590734221181
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.000569442205482
train_x: [ 4.8828125  4.8828125]train_Y:0.01net cost: 0.000549415583937
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 0.000169875793693
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.000520413150258
train_x: [ 4.8828125  4.8828125]train_Y:0.01net cost: 0.000503172639399
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 0.000145566865923
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.000478376260656
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.000993906331164
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 0.000121874671616
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.000435703937484
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.000934114983465
train_x: [ 1.66015625  1.66015625]train_Y:0.0net cost: 0.00090714276654
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.000387811851699
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.000865618189418
train_x: [ 1.66015625  1.66015625]train_Y:0.01net cost: 0.000361900857707
train_x: [ 77.1484375  77.1484375]train_Y:0.0net cost: 0.000827864370466
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.000806561787013
train_x: [ 1.66015625  1.66015625]train_Y:0.0net cost: 0.000786318345832
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.000313141273147
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.000755283441258
train_x: [ 1.66015625  1.66015625]train_Y:0.0net cost: 0.000737482501627
train_x: [ 77.1484375  77.1484375]train_Y:0.0net cost: 0.000720493980632
train_x: [ 4.8828125  4.8828125]train_Y:0.01net cost: 0.000273504350385
train_x: [ 1.66015625  1.66015625]train_Y:0.0net cost: 0.000694550968064
train_x: [ 77.1484375  77.1484375]train_Y:0.0net cost: 0.000679446236598
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.000664978799959
train_x: [ 1.66015625  1.66015625]train_Y:0.0net cost: 0.000651109294879
train_x: [ 77.1484375  77.1484375]train_Y:0.03net cost: 2.25175607811e-05
train_x: [ 4.8828125  4.8828125]train_Y:0.02net cost: 2.81196088535e-05
train_x: [ 1.66015625  1.66015625]train_Y:0.0net cost: 0.000637511639592
train_x: [ 77.1484375  77.1484375]train_Y:0.03net cost: 2.50512968265e-05
train_x: [ 4.8828125  4.8828125]train_Y:0.02net cost: 2.54475610269e-05
train_x: [ 1.66015625  1.66015625]train_Y:0.0net cost: 0.000624719293829
train_x: [ 77.1484375  77.1484375]train_Y:0.0net cost: 0.000612449263562
train_x: [ 4.8828125  4.8828125]train_Y:0.0net cost: 0.000600647809849
train_x: [ 1.66015625  1.66015625]train_Y:0.0net cost: 0.000589288685051
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.00019737040609
train_x: [ 4.8828125  4.8828125]train_Y:0.01net cost: 0.000193764849184
train_x: [ 1.66015625  1.66015625]train_Y:0.0net cost: 0.00056613246476
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.00018441840356
train_x: [ 4.8828125  4.8828125]train_Y:0.02net cost: 1.19725055321e-05
train_x: [ 1.66015625  1.66015625]train_Y:0.01net cost: 0.000180359955669
train_x: [ 77.1484375  77.1484375]train_Y:0.01net cost: 0.000177226986517
train_x: [ 4.8828125  4.8828125]train_Y:0.01net cost: 0.000174178119407
train_x: [ 1.66015625  1.66015625]train_Y:0.01net cost: 0.000171210210821
train_x: [ 77.1484375  77.1484375]train_Y:0.02net cost: 8.84366568952e-06
train_x: [ 4.8828125  4.8828125]train_Y:0.04net cost: 0.000290742910409
train_x: [ 1.66015625  1.66015625]train_Y:0.06net cost: 0.00136216699236
train_x: [ 77.1484375  77.1484375]train_Y:0.05net cost: 0.000707118877219
train_x: [ 4.8828125  4.8828125]train_Y:0.06net cost: 0.00132193781267
train_x: [ 1.66015625  1.66015625]train_Y:0.03net cost: 3.63939113041e-05
train_x: [ 77.1484375  77.1484375]train_Y:0.04net cost: 0.00025528175233
train_x: [ 4.8828125  4.8828125]train_Y:0.05net cost: 0.000667210662755
train_x: [ 1.66015625  1.66015625]train_Y:0.05net cost: 0.000654811719678
train_x: [ 77.1484375  77.1484375]train_Y:0.04net cost: 0.000235492027107
train_x: [ 4.8828125  4.8828125]train_Y:0.02net cost: 2.306749928e-05
train_x: [ 1.66015625  1.66015625]train_Y:0.05net cost: 0.000637260299149
train_x: [ 77.1484375  77.1484375]train_Y:0.03net cost: 2.49710916695e-05
train_x: [ 4.8828125  4.8828125]train_Y:0.06net cost: 0.0012213258309
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 2.91926738821e-05
train_x: [ 77.1484375  77.1484375]train_Y:0.04net cost: 0.000214687363046
train_x: [ 4.8828125  4.8828125]train_Y:0.05net cost: 0.00060037066
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 3.30779158149e-05
train_x: [ 77.1484375  77.1484375]train_Y:0.07net cost: 0.00196329017957
train_x: [ 4.8828125  4.8828125]train_Y:0.02net cost: 3.79279817611e-05
train_x: [ 1.66015625  1.66015625]train_Y:0.04net cost: 0.000193434394617
train_x: [ 77.1484375  77.1484375]train_Y:0.05net cost: 0.000564429037739
train_x: [ 4.8828125  4.8828125]train_Y:0.04net cost: 0.000182181931273
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 4.42613605634e-05
train_x: [ 77.1484375  77.1484375]train_Y:0.0net cost: 0.000706404832663
train_x: [ 4.8828125  4.8828125]train_Y:0.02net cost: 3.94747958277e-05
train_x: [ 1.66015625  1.66015625]train_Y:0.01net cost: 0.000262903067463
train_x: [ 77.1484375  77.1484375]train_Y:0.0net cost: 0.00067800184802
train_x: [ 4.8828125  4.8828125]train_Y:0.03net cost: 1.79747905065e-05
train_x: [ 1.66015625  1.66015625]train_Y:0.03net cost: 1.75984207628e-05
train_x: [ 77.1484375  77.1484375]train_Y:0.08net cost: 0.00293230339401
train_x: [ 4.8828125  4.8828125]train_Y:0.03net cost: 1.27539096345e-05
train_x: [ 1.66015625  1.66015625]train_Y:0.02net cost: 4.18380967038e-05
train_x: [ 77.1484375  77.1484375]train_Y:0.07net cost: 0.00190125339932
train_x: [ 4.8828125  4.8828125]train_Y:0.03net cost: 9.72386171166e-06
train_x: [ 1.66015625  1.66015625]train_Y:0.04net cost: 0.000171156196955
train_x: [ 77.1484375  77.1484375]train_Y:0.06net cost: 0.00108454537543
train_x: [ 4.8828125  4.8828125]train_Y:0.02net cost: 5.5523721923e-05
train_x: [ 1.66015625  1.66015625]train_Y:0.06net cost: 0.00106517949685
train_x: [ 77.1484375  77.1484375]train_Y:0.03net cost: 5.05608880025e-06
train_x: [ 4.8828125  4.8828125]train_Y:0.06net cost: 0.00103820833859
train_x: [ 1.66015625  1.66015625]train_Y:0.03net cost: 3.33534514107e-06
train_x: [ 77.1484375  77.1484375]train_Y:0.02net cost: 6.71836892392e-05
train_x: [ 4.8828125  4.8828125]train_Y:0.05net cost: 0.000479871299454
train_x: [ 1.66015625  1.66015625]train_Y:0.04net cost: 0.000135305887369
train_x: [ 77.1484375  77.1484375]train_Y:0.06net cost: 0.000991258030931
train_x: [ 4.8828125  4.8828125]train_Y:0.04net cost: 0.000122727597958
train_x: [ 1.66015625  1.66015625]train_Y:0.01Traceback (most recent call last):
  File "adaptNN.py", line 307, in <module>
    main()
  File "adaptNN.py", line 85, in main
    train_x, prediction, network_cost, network_output, param_cost = net.train_batch(train_data, learning_rate1=1.5, learning_rate2=5.5, mod = modify, batch_size=batch_size)
  File "adaptNN.py", line 268, in train_batch
    on_unused_input='ignore')
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/compile/function.py", line 320, in function
    output_keys=output_keys)
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/compile/pfunc.py", line 479, in pfunc
    output_keys=output_keys)
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/compile/function_module.py", line 1777, in orig_function
    defaults)
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/compile/function_module.py", line 1641, in create
    input_storage=input_storage_lists, storage_map=storage_map)
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/gof/link.py", line 690, in make_thunk
    storage_map=storage_map)[:3]
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/gof/vm.py", line 1003, in make_all
    no_recycling))
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/gof/op.py", line 970, in make_thunk
    no_recycling)
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/gof/op.py", line 870, in make_c_thunk
    e = FunctionGraph(node.inputs, node.outputs)
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/gof/fg.py", line 171, in __init__
    self.__import_r__(output, reason="init")
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/gof/fg.py", line 360, in __import_r__
    self.__import__(variable.owner, reason=reason)
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/gof/fg.py", line 489, in __import__
    self.execute_callbacks('on_import', node, reason)
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/gof/fg.py", line 673, in execute_callbacks
    fn(self, *args, **kwargs)
  File "/usr/local/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/gof/toolbox.py", line 377, in on_import
    if node in self._nodes_removed:
KeyboardInterrupt
